\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}   % Кодировка ввода
\usepackage[T2A]{fontenc}     % Кодировка шрифтов
\usepackage[russian]{babel}   % Поддержка русского языка
\usepackage{amsmath, amssymb} % Пакеты для математических формул
\usepackage{graphicx}         % Вставка изображений
\usepackage{hyperref}         % Гиперссылки
\usepackage{geometry}         % Пакет для управления размерами полей
\geometry{
  top=2cm,
  bottom=2cm,
  left=3cm,
  right=1.5cm
}

\begin{document}
%--------------------- Титульный лист ------------------------
\thispagestyle{empty}
\begin{center}
\Large Санкт-Петербургский политехнический университет Петра Великого\\
\vspace{0.5em}
Физико-механический институт\\
Кафедра прикладной математики и информатики\\[2.5cm]


\Large \textbf{Отчёт по лабораторной работе №1}\\
\Large \textbf{По дисциплине "Дискретная математика"}

\Large Тема : «Алгоритм Фано»\\[4cm]

\vfill
\begin{flushright}
Выполнил студент гр. 5030102/30401\\
\textbf{Кулиев~Х.~Т.}\\[1em]

\end{flushright}
\vfill
Санкт-Петербург \\[0.5em]
2025~г.
\end{center}
\newpage
\section{Цель и задачи работы}

Целью данной лабораторной работы является реализация алгоритма Фано — метода неравномерного префиксного кодирования символов на основе их вероятностей появления в тексте. 

В рамках работы требуется:
\item реализовать процедуры кодирования и декодирования текста с использованием алгоритма Фано;
    \item обеспечить вывод промежуточных кодов на экран как при кодировании, так и при декодировании для контроля корректности работы алгоритма;
    \item провести сравнительный анализ эффективности полученного кодирования с равномерным кодированием (ASCII) на текстах разной длины;
    \item сделать выводы об эффективности алгоритма Фано в зависимости от статистических свойств входного текста.
\end{itemize}
\section{Описание алгоритма Фано}

Алгоритм Фано — это метод построения префиксного кода, основанный на рекурсивном разбиении множества символов на две подгруппы с максимально близкими суммарными вероятностями. Цель разбиения — приблизить среднюю длину кода к энтропии источника, что обеспечивает высокую эффективность сжатия.

\subsection{Основные шаги алгоритма}

\begin{enumerate}
    \item \textbf{Подсчёт частот и вероятностей}: для каждого символа во входном тексте вычисляется частота появления и вероятность $p_i = \frac{n_i}{N}$, где $n_i$ — количество вхождений символа, $N$ — общая длина текста.
    
    \item \textbf{Сортировка}: все символы сортируются по убыванию вероятности.
    
    \item \textbf{Рекурсивное разбиение}: отсортированный список символов разбивается на две части так, чтобы разность между суммами вероятностей в левой и правой частях была минимальной. Это делается функцией \texttt{\_med}.
    
    \item \textbf{Присвоение битов}: символам первой (левой) части добавляется бит «0» к текущему коду, символам второй (правой) — бит «1».
    
    \item \textbf{Рекурсия}: процедура повторяется для каждой из двух частей до тех пор, пока в подсписке не останется один символ. В этот момент формирование кода для этого символа завершено.
\end{enumerate}

\subsection{Особенности реализации}

В данной реализации:
\item Используется класс \texttt{FanoEncoder}, инкапсулирующий логику кодирования и декодирования.
    \item Построение кодов выполняется в методе \texttt{\_build\_codes}, который вызывает рекурсивную функцию \texttt{\_fano\_recursive}.
    \item Декодирование осуществляется с помощью обратного словаря «код $\rightarrow$ символ» и последовательного чтения битов до совпадения с одним из кодов.
    \item Все этапы сопровождаются подробным выводом на экран (если включён режим \texttt{verbose}), что позволяет отслеживать корректность работы.

Алгоритм гарантирует получение \textbf{префиксного кода}, то есть ни один код не является началом другого, что обеспечивает однозначное декодирование без разделителей.
\end{itemize}
\section{Демонстрация работы алгоритма}

Алгоритм был протестирован на трёх текстах разной длины: коротком (13 символов), среднем (245 символов) и длинном (5270 символов). Ниже приведены результаты.

\subsection{Короткий текст: \texttt{"Hello, World!"} (13 символов)}

Исходный текст: \texttt{"Hello, World!"}

\textbf{Вероятности символов (отсортированы по убыванию):}
\begin{center}
\begin{tabular}{|l|r|r|}
\hline
Символ & Вероятность & Частота \\
\hline
l & 0.230769 & 3 \\
o & 0.153846 & 2 \\
H, e, ,, \texttt{' '}, W, r, d, ! & 0.076923 & 1 \\
\hline
\end{tabular}
\end{center}

\textbf{Построенные коды Фано:}
\begin{center}
\begin{tabular}{|l|l|r|r|}
\hline
Символ & Код & Длина & $p \cdot l$ \\
\hline
l & 00 & 2 & 0.4615 \\
o & 010 & 3 & 0.4615 \\
H & 011 & 3 & 0.2308 \\
r & 110 & 3 & 0.2308 \\
e & 1000 & 4 & 0.3077 \\
, & 1001 & 4 & 0.3077 \\
\texttt{' '} & 1010 & 4 & 0.3077 \\
W & 1011 & 4 & 0.3077 \\
d & 1110 & 4 & 0.3077 \\
! & 1111 & 4 & 0.3077 \\
\hline
\end{tabular}
\end{center}

Средняя длина кода: \textbf{3.2308 бит/символ}.

\textbf{Кодирование первых символов:}
\item H → 011,\quad e → 1000,\quad l → 00,\quad l → 00,\quad o → 010,\quad , → 1001,\quad \texttt{' '} → 1010,\quad \dots

Закодированная строка (42 бита):  
\texttt{011100000000101001101010110101100011101111}

\textbf{Декодирование} полностью восстановил исходный текст.

\textbf{Сравнение с ASCII:}
\item ASCII: 104 бита (13 байт)
    \item Фано: 42 бита (5.25 байт)
    \item Теоретический минимум: 41 бит
    \item Коэффициент сжатия: \textbf{59.62\%}
    \item Эффективность относительно энтропии: \textbf{98.45\%}

\subsection{Средний текст (245 символов)}

Текст содержит повторяющиеся фразы на русском языке. Алгоритм корректно построил префиксные коды для 22 уникальных символов и успешно выполнил кодирование и декодирование.

\textbf{Результаты:}
\item Длина текста: 245 символов
    \item Закодировано: \textbf{1045 бит} (вместо 1960 бит в ASCII)
    \item Энтропия: 4.2262 бит/символ
    \item Средняя длина кода: 4.2653 бит/символ
    \item Коэффициент сжатия: \textbf{46.68\%}
    \item Эффективность относительно энтропии: \textbf{99.08\%}

\subsection{Длинный текст (5270 символов)}

Текст представляет собой многократно повторённый технический фрагмент с использованием кириллицы, знаков препинания и пробелов (43 уникальных символа). Кодирование и декодирование прошли без ошибок.

\textbf{Результаты:}
\item Длина текста: 5270 символов
    \item Закодировано: \textbf{23080 бит} (вместо 42160 бит в ASCII)
    \item Энтропия: 4.3543 бит/символ
    \item Средняя длина кода: 4.3795 бит/символ
    \item Коэффициент сжатия: \textbf{45.26\%}
    \item Эффективность относительно энтропии: \textbf{99.42\%}
    \end{itemize}
    \section{Анализ устойчивости и возможных сбоев}

Реализованная программа демонстрирует высокую устойчивость при выполнении в рамках поставленной задачи. Рассмотрим условия, при которых возможны сбои, и случаи гарантированно корректной работы.

\subsection{Случаи корректной работы}

Программа корректно обрабатывает:
\item тексты любой длины (включая односимвольные);
    \item тексты с произвольным набором символов: латиница, кириллица, цифры, знаки препинания, пробелы, символы перевода строки (\texttt{\textbackslash n}) и табуляции (\texttt{\textbackslash t});
    \item тексты с высокой и низкой неравномерностью распределения символов.

Во всех проведённых тестах (включая интерактивный ввод) проверка \texttt{decoded == original} завершилась успешно, что подтверждает корректность как кодирования, так и декодирования.

\subsection{Потенциальные сбои}

Сбои могут возникнуть только при нарушении условий эксплуатации:
\item \textbf{Декодирование «чужой» битовой строки}. Если на вход методу \texttt{decode()} подать битовую последовательность, не полученную с помощью того же экземпляра \texttt{FanoEncoder} (например, случайную строку или результат другого кодировщика), алгоритм может:
    \begin{itemize}
        \item зависнуть (если ни один префикс не совпадает с известными кодами);
        \item выдать неполный или искажённый текст (если частичные совпадения приведут к ложному распознаванию).
    Однако в рамках лабораторной работы декодирование всегда применяется к корректно закодированной строке, поэтому такие ситуации исключены.
    
    \item \textbf{Пустой входной текст}. В текущей реализации пустая строка обрабатывается без ошибок: список вероятностей оказывается пустым, кодирование возвращает пустую битовую строку, декодирование — пустой текст. Таким образом, даже этот крайний случай обработан корректно.
\end{itemize}
\section{Формат входных и выходных данных}

В рамках реализации алгоритма Фано входные и выходные данные представлены в следующем виде:

\subsection{Входные данные}
Программа поддерживает два способа задания входного текста:
\begin{enumerate}
    \item \textbf{Автоматическое тестирование}: три заранее определённых текста (короткий, средний, длинный) передаются программно.
    \item \textbf{Интерактивный ввод}: после завершения автоматических тестов пользователю выводится приглашение:
    \begin{quote}
        \texttt{Введите свой текст для кодирования (или оставьте пустым для выхода):}
    \end{quote}
    и ожидается ввод строки через стандартный поток ввода (\texttt{stdin}).
\end{enumerate}

В обоих случаях входными данными является \textbf{строка текста произвольной длины}, содержащая:
\item буквы латинского и кириллического алфавитов (в любом регистре);
    \item цифры, знаки препинания, пробелы;
    \item специальные символы: символ перевода строки (\texttt{\textbackslash n}), табуляции (\texttt{\textbackslash t}) и другие допустимые символы кодировки UTF-8.
Данные передаются в оперативной памяти как объект типа \texttt{str} в языке Python.

\subsection{Выходные данные}
Программа формирует следующие выходные данные:
\item \textbf{Словарь кодов}: соответствие «символ → битовая строка», хранится в атрибуте \texttt{codes} как \texttt{Dict[str, str]}.
    \item \textbf{Закодированная строка}: последовательность битов, представленная строкой из символов \texttt{'0'} и \texttt{'1'}.
    \item \textbf{Декодированный текст}: строка, идентичная входной (при корректном кодировании).
    \item \textbf{Статистическая информация}: энтропия источника, средняя длина кода, коэффициент сжатия, эффективность относительно энтропии — выводится на экран в человекочитаемом виде.
Все выходные данные выводятся через стандартный поток вывода (\texttt{stdout}). Файловый ввод/вывод не используется.
\section{Выполнение дополнительных требований по заданию}

В соответствии с вариантом задания была реализована возможность вывода кодов на экран как при кодировании, так и при декодировании, что позволило наглядно отслеживать корректность работы алгоритма на каждом этапе.

Кроме того, был проведён сравнительный анализ эффективности алгоритма Фано с равномерным кодированием (ASCII) на трёх текстах разной длины. Результаты представлены в таблице~\ref{tab:comparison}.

\begin{table}[h]
\centering
\caption{Сравнение эффективности кодирования Фано и ASCII}
\label{tab:comparison}
\begin{tabular}{|l|r|r|r|r|}
\hline
Текст & Длина & ASCII (бит) & Фано (бит) & Сжатие \\
\hline
Короткий & 13 & 104 & 42 & 59.62\% \\
Средний & 245 & 1960 & 1045 & 46.68\% \\
Длинный & 5270 & 42160 & 23080 & 45.26\% \\
\hline
\end{tabular}
\end{table}

\textbf{Выводы об эффективности:}
\item Алгоритм Фано обеспечивает значительное сжатие по сравнению с ASCII: от \textbf{45\% до 60\%} в зависимости от статистики текста.
    \item Наибольший коэффициент сжатия достигается на коротких текстах с высокой неравномерностью распределения символов (например, повторяющаяся буква «l» в «Hello, World!»).
    \item На длинных текстах с естественным языковым распределением сжатие стабилизируется около \textbf{45\%}, что соответствует теоретическим ожиданиям для русскоязычных текстов.
    \item Средняя длина кода Фано отличается от энтропии менее чем на \textbf{1\%}, что свидетельствует о высокой близости к оптимальному кодированию.
    \item Во всех случаях декодирование полностью восстанавливало исходный текст, что подтверждает корректность реализации.


\end{itemize}

\end{document}
